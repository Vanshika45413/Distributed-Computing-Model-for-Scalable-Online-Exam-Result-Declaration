import time
import random
import threading
import redis
from queue import Queue # For simulating message passing between replicas

# --- Configuration ---
NUM_ZONES = 3
SERVERS_PER_CLUSTER = 10
CLUSTERS_PER_ZONE = 6
ZONE_NAMES = {
    0: "North Mumbai",
    1: "Central Mumbai",
    2: "South Mumbai"
}
DATA_CENTERS = {
    "North Mumbai": "Data Center 01",
    "Central Mumbai": "Data Center 02",
    "South Mumbai": "Data Center 03"
}
NUM_REPLICAS_PER_SHARD = 3 # <--- New config
ELECTION_TIMEOUT = 0.5    # <--- Timeout for waiting for OK messages (seconds)
HEARTBEAT_INTERVAL = 2.0 # <--- How often to check leader status (seconds)
FAILURE_PROBABILITY = 0.1 # <--- Chance leader fails during a check

# --- Locks ---
print_lock = threading.Lock() # To make print output less jumbled

def locked_print(*args, **kwargs):
    """Helper function for thread-safe printing."""
    with print_lock:
        print(*args, **kwargs)

# --- Redis Connection ---
try:
    redis_client = redis.Redis(host='localhost', port=6379, db=0, decode_responses=True)
    redis_client.ping()
    locked_print("Successfully connected to Redis.")
except redis.exceptions.ConnectionError as e:
    locked_print(f"Error connecting to Redis: {e}")
    locked_print("Please ensure Redis server is running on localhost:6379.")
    exit()

# --- Helper Function for Redis Keys ---
def get_cluster_load_key(cluster_id):
    return f"cluster:load:{cluster_id}"

# --- DatabaseReplica Class ---
class DatabaseReplica:
    def __init__(self, shard_id, replica_id, all_replica_proxies):
        self.shard_id = shard_id
        self.replica_id = replica_id # My unique ID (0, 1, 2...)
        self.all_replica_proxies = all_replica_proxies # Dict {rep_id: replica_obj} in this shard
        self.state = "UP" # Can be "UP" or "DOWN"
        self.current_leader_id = NUM_REPLICAS_PER_SHARD - 1 # Assume highest ID is leader initially
        self.is_election_active = False
        self.election_lock = threading.Lock() # Protect election state
        self.message_queue = Queue() # Simulate receiving messages
        self.data = {} # Each replica holds a copy of the data (simplified)
        self.ok_received_event = threading.Event()

        # Pre-populate some data specific to the shard
        for i in range(100): # Smaller sample data for replicas
            roll_num = f"R{i:03d}{self.shard_id}"
            self.data[roll_num] = f"Result for {roll_num} from Shard {self.shard_id} (Replica {self.replica_id})"

    def _send_message(self, target_replica_id, message_type, sender_id):
        """Simulates sending a message to another replica's queue."""
        if target_replica_id in self.all_replica_proxies:
            target_replica = self.all_replica_proxies[target_replica_id]
            if target_replica.state == "UP":
                target_replica.message_queue.put((message_type, sender_id))
                # locked_print(f"[Replica S{self.shard_id}R{self.replica_id}] Sent {message_type} to R{target_replica_id}")

    def process_messages(self):
        """Process incoming messages from the queue."""
        while not self.message_queue.empty():
            message_type, sender_id = self.message_queue.get()
            if self.state != "UP": continue # Ignore messages if down

            # locked_print(f"[Replica S{self.shard_id}R{self.replica_id}] Received {message_type} from R{sender_id}")
            if message_type == "ELECTION":
                self._handle_election_message(sender_id)
            elif message_type == "OK":
                self._handle_ok_message(sender_id)
            elif message_type == "COORDINATOR":
                self._handle_coordinator_message(sender_id) # sender_id is the new leader

    def _handle_election_message(self, sender_id):
        """Handles receiving an ELECTION message."""
        # Reply OK if my ID is higher
        if self.replica_id > sender_id:
            self._send_message(sender_id, "OK", self.replica_id)
            # Start my own election if one isn't already running
            self.initiate_election("received election from lower ID")

    def _handle_ok_message(self, sender_id):
        """Handles receiving an OK message."""
        # If I receive an OK, it means someone higher is alive.
        # I stop waiting to become leader in this election round.
        # locked_print(f"[Replica S{self.shard_id}R{self.replica_id}] Received OK from R{sender_id}, stopping my bid.")
        self.ok_received_event.set() # Signal that an OK was received

    def _handle_coordinator_message(self, new_leader_id):
        """Handles receiving a COORDINATOR message."""
        with self.election_lock:
            if new_leader_id != self.current_leader_id:
                locked_print(f"[Replica S{self.shard_id}R{self.replica_id}] Acknowledging NEW LEADER: R{new_leader_id}")
                self.current_leader_id = new_leader_id
            self.is_election_active = False # Election is over

    def initiate_election(self, reason=""):
        """Starts the leader election process."""
        with self.election_lock:
            if self.is_election_active:
                # locked_print(f"[Replica S{self.shard_id}R{self.replica_id}] Election already active, ignoring trigger ({reason}).")
                return False # Don't start if already running
            locked_print(f"[Replica S{self.shard_id}R{self.replica_id}] !!! Initiating ELECTION ({reason}) !!!")
            self.is_election_active = True
            self.ok_received_event.clear() # Reset the event for this round

        higher_replicas_exist = False
        for rep_id in self.all_replica_proxies:
            if rep_id > self.replica_id:
                higher_replicas_exist = True
                self._send_message(rep_id, "ELECTION", self.replica_id)

        if not higher_replicas_exist:
            # If no one has a higher ID, I am the leader by default
            locked_print(f"[Replica S{self.shard_id}R{self.replica_id}] No higher IDs exist, declaring myself leader.")
            self._declare_victory()
            return True

        # Wait for OK messages for a short timeout
        # Use threading.Timer to avoid blocking message processing
        timer = threading.Timer(ELECTION_TIMEOUT, self._check_election_result)
        timer.start()
        return True

    def _check_election_result(self):
        """Called after the timeout to see if OK was received."""
        if not self.is_election_active: # Check if election was cancelled by Coordinator message
            return

        if not self.ok_received_event.is_set():
            # Timeout occurred and NO "OK" received - I am the leader!
            locked_print(f"[Replica S{self.shard_id}R{self.replica_id}] Timeout reached, no OK received. Declaring victory!")
            self._declare_victory()
        else:
            # OK was received, someone else higher is taking over. Wait for COORDINATOR.
            locked_print(f"[Replica S{self.shard_id}R{self.replica_id}] Election timed out, but OK was received. Waiting for new leader.")
            # Reset election status but wait for coordinator message
            with self.election_lock:
                 self.is_election_active = False # My bid is over


    def _declare_victory(self):
        """Declares self as leader and sends COORDINATOR messages."""
        with self.election_lock:
            if self.state != "UP": # Cannot become leader if down
                self.is_election_active = False
                return
            locked_print(f"[Replica S{self.shard_id}R{self.replica_id}] +++ Declaring MYSELF (R{self.replica_id}) as LEADER! +++")
            self.current_leader_id = self.replica_id
            self.is_election_active = False # Election process finished

        # Send COORDINATOR message to all other replicas
        for rep_id in self.all_replica_proxies:
            if rep_id != self.replica_id:
                self._send_message(rep_id, "COORDINATOR", self.replica_id) # Send my ID as new leader

    def get_result(self, roll_number):
        """Simulates reading data from this replica."""
        if self.state != "UP":
             raise ConnectionError(f"Replica S{self.shard_id}R{self.replica_id} is DOWN")
        # locked_print(f"      [Replica S{self.shard_id}R{self.replica_id}] Accessing data for {roll_number}")
        time.sleep(random.uniform(0.05, 0.1)) # Simulate DB lookup time on replica
        return self.data.get(roll_number, "Result Not Found")

    def check_leader_health(self):
        """Periodically checks leader status and starts election if needed."""
        if self.state != "UP" or self.is_election_active:
            return # Don't check if down or already in election

        leader = self.all_replica_proxies.get(self.current_leader_id)

        # Simple check: Is the leader object marked DOWN?
        if not leader or leader.state == "DOWN":
            locked_print(f"[Replica S{self.shard_id}R{self.replica_id}] Detected LEADER R{self.current_leader_id} is DOWN!")
            self.initiate_election("leader detected down")
        # else:
        #     locked_print(f"[Replica S{self.shard_id}R{self.replica_id}] Leader R{self.current_leader_id} seems OK.")

    def simulate_failure(self):
        """Marks this replica as DOWN."""
        if self.state == "UP":
            locked_print(f"[Replica S{self.shard_id}R{self.replica_id}] !!! SIMULATING FAILURE - GOING DOWN !!!")
            self.state = "DOWN"
            # If I was the leader, other replicas should detect this via check_leader_health
            with self.election_lock:
                 self.is_election_active = False # Stop any election I might have been running

    def simulate_recovery(self):
       """Marks replica as UP and potentially starts election."""
       if self.state == "DOWN":
           locked_print(f"[Replica S{self.shard_id}R{self.replica_id}] >>> SIMULATING RECOVERY - COMING UP <<<")
           self.state = "UP"
           # When recovering, initiate an election to potentially become leader if highest ID
           self.initiate_election("recovered from failure")


# --- DatabaseShard Class ---
class DatabaseShard:
    def __init__(self, shard_id):
        self.shard_id = shard_id
        self.replicas = {} # {replica_id: DatabaseReplica object}
        self.leader_check_thread = None
        self.message_processor_thread = None
        self.stop_event = threading.Event()
        self.leader_id_lock = threading.Lock() # Protect access to _current_leader_id
        self._current_leader_id = NUM_REPLICAS_PER_SHARD - 1 # Assume highest is leader initially

        locked_print(f"[Shard S{self.shard_id}] Initializing {NUM_REPLICAS_PER_SHARD} replicas...")
        for i in range(NUM_REPLICAS_PER_SHARD):
            self.replicas[i] = DatabaseReplica(shard_id, i, self.replicas)
            locked_print(f"  [Shard S{self.shard_id}] Created Replica R{i}")

        # Start background threads for this shard
        self.start_background_tasks()

    def get_current_leader(self):
        """Safely get the current leader replica object."""
        with self.leader_id_lock:
            leader_id = self._current_leader_id
            # Update leader ID based on replica's knowledge (if coordinator msg received)
            # This is a bit simplified; ideally, shard itself confirms leader state
            if leader_id in self.replicas:
                 rep = self.replicas[leader_id]
                 if rep.state == "UP":
                    if rep.current_leader_id != leader_id:
                         self._current_leader_id = rep.current_leader_id
                         leader_id = self._current_leader_id
            # Ensure the chosen leader is actually UP
            leader_replica = self.replicas.get(leader_id)
            if leader_replica and leader_replica.state == "UP":
                return leader_replica
            else:
                # Current leader is down or unknown, find *any* UP replica (might be wrong leader briefly)
                # Bully election should correct this shortly
                for rep in self.replicas.values():
                    if rep.state == "UP":
                        # locked_print(f"[Shard S{self.shard_id}] WARN: Leader R{leader_id} down/unknown, using backup R{rep.replica_id}")
                        return rep
                return None # No replicas available

    def get_result(self, roll_number):
        """Get result from the current leader replica."""
        leader_replica = self.get_current_leader()
        if leader_replica:
            thread_name = threading.current_thread().name
            locked_print(f"      [Shard S{self.shard_id}] (Thread: {thread_name}) Forwarding read for {roll_number} to LEADER Replica R{leader_replica.replica_id}")
            try:
                return leader_replica.get_result(roll_number)
            except ConnectionError as e:
                locked_print(f"      [Shard S{self.shard_id}] (Thread: {thread_name}) Error contacting leader R{leader_replica.replica_id}: {e}")
                # In a real system, might retry or trigger election faster
                return "Error: Database temporarily unavailable"
        else:
            locked_print(f"      [Shard S{self.shard_id}] (Thread: {thread_name}) CRITICAL: No UP replicas available for {roll_number}!")
            return "Error: Database unavailable"

    def _run_leader_checks(self):
        """Background task to periodically check leader health and trigger failures."""
        while not self.stop_event.is_set():
            time.sleep(HEARTBEAT_INTERVAL)
            if self.stop_event.is_set(): break

            # Pick a random UP replica to perform the health check
            up_replicas = [r for r in self.replicas.values() if r.state == "UP"]
            if not up_replicas: continue
            checker = random.choice(up_replicas)
            checker.check_leader_health()

            # Simulate leader failure randomly
            current_leader = self.replicas.get(self._current_leader_id)
            if current_leader and current_leader.state == "UP":
                 if random.random() < FAILURE_PROBABILITY:
                     locked_print(f"[Shard S{self.shard_id}] *** Randomly failing leader R{self._current_leader_id} ***")
                     current_leader.simulate_failure()

    def _run_message_processing(self):
        """Background task to process message queues for all replicas."""
        while not self.stop_event.is_set():
            processed_message = False
            for replica in self.replicas.values():
                if replica.state == "UP" and not replica.message_queue.empty():
                    replica.process_messages()
                    processed_message = True
            if not processed_message:
                 time.sleep(0.1) # Avoid busy-waiting if queues are empty
            if self.stop_event.is_set(): break


    def start_background_tasks(self):
        self.stop_event.clear()
        # Thread to check leader health / simulate failures
        self.leader_check_thread = threading.Thread(target=self._run_leader_checks, daemon=True)
        self.leader_check_thread.start()
        # Thread to process messages for replicas
        self.message_processor_thread = threading.Thread(target=self._run_message_processing, daemon=True)
        self.message_processor_thread.start()
        locked_print(f"[Shard S{self.shard_id}] Started background tasks (Health Check, Msg Proc).")


    def shutdown(self):
        locked_print(f"[Shard S{self.shard_id}] Shutting down background tasks...")
        self.stop_event.set()
        if self.leader_check_thread: self.leader_check_thread.join(timeout=HEARTBEAT_INTERVAL + 0.5)
        if self.message_processor_thread: self.message_processor_thread.join(timeout=0.5)
        locked_print(f"[Shard S{self.shard_id}] Background tasks stopped.")


# --- ApplicationServer Class ---
class ApplicationServer:
    _server_count = 0
    def __init__(self, zone_name, db_shard, cluster_id, redis_conn): # db_shard is now the manager object
        self.server_id = f"S{ApplicationServer._server_count:03d}"
        ApplicationServer._server_count += 1
        self.zone_name = zone_name
        self.db_shard = db_shard # This is the DatabaseShard manager object
        self.cluster_id = cluster_id
        self.redis_conn = redis_conn
        self.cluster_load_key = get_cluster_load_key(self.cluster_id)
        try:
            self.redis_conn.zadd(self.cluster_load_key, {self.server_id: 0}, nx=True)
        except redis.exceptions.RedisError as e:
            locked_print(f"    [App Server {self.server_id}] Redis Error initializing load: {e}")

    def handle_request(self, roll_number):
        current_load = self.get_load_from_redis()
        thread_name = threading.current_thread().name
        locked_print(f"    [App Server {self.server_id} @ {self.zone_name}] (Thread: {thread_name}) Received request for {roll_number}. Current Load (Redis): {current_load}")

        time.sleep(random.uniform(0.1, 0.3)) # Simulate processing time

        # Ask the shard manager for the result (it talks to the leader replica)
        result = self.db_shard.get_result(roll_number)

        locked_print(f"    [App Server {self.server_id} @ {self.zone_name}] (Thread: {thread_name}) Processed request for {roll_number}. Sending result.")
        return result

    def increment_load_in_redis(self):
        try:
            self.redis_conn.zincrby(self.cluster_load_key, 1, self.server_id)
        except redis.exceptions.RedisError as e: print(f"Redis Error: {e}")
    def decrement_load_in_redis(self):
        try:
            new_load = self.redis_conn.zincrby(self.cluster_load_key, -1, self.server_id)
            if new_load < 0: self.redis_conn.zadd(self.cluster_load_key, {self.server_id: 0})
        except redis.exceptions.RedisError as e: print(f"Redis Error: {e}")
    def get_load_from_redis(self):
        try:
            score = self.redis_conn.zscore(self.cluster_load_key, self.server_id)
            return int(float(score)) if score is not None else 0
        except redis.exceptions.RedisError as e: return -1


# --- CLB, ZLB, PLB Classes ---
class ClusterLoadBalancer:
    _clb_count = 0
    def __init__(self, zone_name, servers_dict, redis_conn):
        self.clb_id = f"CLB{ClusterLoadBalancer._clb_count:02d}"
        ClusterLoadBalancer._clb_count += 1
        self.zone_name = zone_name
        if not servers_dict: raise ValueError("CLB must manage servers.")
        self.servers = servers_dict
        self.redis_conn = redis_conn
        self.cluster_load_key = get_cluster_load_key(self.clb_id)

    def select_server_id_from_redis(self):
        try:
            results = self.redis_conn.zrange(self.cluster_load_key, 0, 0, withscores=True)
            if results: return results[0][0]
            else: return random.choice(list(self.servers.keys())) if self.servers else None
        except redis.exceptions.RedisError as e: return None

    def forward_request(self, roll_number):
        thread_name = threading.current_thread().name
        # locked_print(f"  [CLB {self.clb_id} @ {self.zone_name}] (Thread: {thread_name}) Received request for {roll_number}. Finding best server via Redis...")
        target_server_id = self.select_server_id_from_redis()
        if target_server_id and target_server_id in self.servers:
            target_server = self.servers[target_server_id]
            target_server.increment_load_in_redis()
            result = None
            try:
                # locked_print(f"  [CLB {self.clb_id}] (Thread: {thread_name}) Forwarding request for {roll_number} to Server {target_server.server_id}")
                result = target_server.handle_request(roll_number)
            finally:
                target_server.decrement_load_in_redis()
                # locked_print(f"  [CLB {self.clb_id}] (Thread: {thread_name}) Request for {roll_number} completed by Server {target_server.server_id}. Load decremented in Redis.")
            return result
        else: return "Error: Service Unavailable (CLB)"

    def get_total_load_from_redis(self):
        try:
            all_loads = self.redis_conn.zrange(self.cluster_load_key, 0, -1, withscores=True)
            return sum(score for _, score in all_loads)
        except redis.exceptions.RedisError: return float('inf')

class ZoneLoadBalancer:
     def __init__(self, zone_id, zone_name, clbs, redis_conn):
        self.zone_id = zone_id; self.zone_name = zone_name; self.data_center = DATA_CENTERS[zone_name]
        if not clbs: raise ValueError("ZLB must manage CLBs.")
        self.clbs = clbs; self.redis_conn = redis_conn
        locked_print(f" [ZLB {self.zone_name}] Initialized, managing {len(self.clbs)} CLBs.")

     def select_clb(self):
        min_load = float('inf'); chosen_clb = None; loads = {}
        for clb in self.clbs:
             load = clb.get_total_load_from_redis(); loads[clb.clb_id] = load
             if load < min_load: min_load = load; chosen_clb = clb
             elif load == min_load and chosen_clb: chosen_clb = random.choice([clb, chosen_clb])
        return chosen_clb

     def forward_request(self, roll_number):
        thread_name = threading.current_thread().name
        # locked_print(f" [ZLB {self.zone_name}] (Thread: {thread_name}) Received request for {roll_number}. Finding best CLB...")
        target_clb = self.select_clb()
        if target_clb: return target_clb.forward_request(roll_number)
        else: return "Error: Zone Unavailable (ZLB)"

class PrimaryLoadBalancer:
    def __init__(self, zl_balancers):
        self.zl_balancers = zl_balancers
        locked_print(f"[PLB] Initialized. Managing Zones: {list(self.zl_balancers.keys())}")

    def get_zone_for_request(self, roll_number):
        try: zone_index = int(roll_number[-1]) % NUM_ZONES; return ZONE_NAMES.get(zone_index, ZONE_NAMES[0])
        except: return ZONE_NAMES[0]

    def handle_request(self, roll_num):
        thread_name = threading.current_thread().name
        # locked_print(f"\n[PLB] (Thread: {thread_name}) Received request for Roll Number: {roll_num}")
        target_zone = self.get_zone_for_request(roll_num)
        # locked_print(f"[PLB] (Thread: {thread_name}) Determined Zone for {roll_num}: {target_zone}")
        if target_zone in self.zl_balancers:
            zlb = self.zl_balancers[target_zone]
            # locked_print(f"[PLB] (Thread: {thread_name}) Forwarding request for {roll_num} to ZLB for {target_zone}")
            return zlb.forward_request(roll_num)
        else: return "Error: Invalid Zone (PLB)"

# --- System Setup ---
def setup_system(redis_conn):
    locked_print("\n--- System Setup (with Bully Algorithm) ---")
    # Clear Redis keys
    locked_print("Clearing existing cluster load keys in Redis...")
    prefix = get_cluster_load_key("CLB*").split('*')[0] # Get prefix like 'cluster:load:CLB'
    keys_to_delete = redis_conn.keys(f"{prefix}*")
    if keys_to_delete:
         redis_conn.delete(*keys_to_delete)
         # locked_print(f"  Deleted {len(keys_to_delete)} Redis keys matching {prefix}*")

    ApplicationServer._server_count = 0
    ClusterLoadBalancer._clb_count = 0

    # 1. Create Database Shards (each managing its replicas)
    db_shards = [DatabaseShard(shard_id=i) for i in range(NUM_ZONES)]
    locked_print(f"Created {len(db_shards)} Database Shards (each with {NUM_REPLICAS_PER_SHARD} replicas).")

    # 2. Create Application Servers (pass the appropriate shard manager)
    all_servers = []; servers_by_zone = {zn: [] for zn in ZONE_NAMES.values()}; servers_for_clb = {}
    temp_clb_counter = 0
    for zone_id in range(NUM_ZONES):
        zone_name = ZONE_NAMES[zone_id]
        db_shard_manager = db_shards[zone_id] # Get the manager for this zone's shard
        for clb_idx_in_zone in range(CLUSTERS_PER_ZONE):
             clb_id = f"CLB{temp_clb_counter:02d}"; servers_for_clb[clb_id] = {}
             for _ in range(SERVERS_PER_CLUSTER):
                 # Pass the SHARD MANAGER object, not a replica
                 server = ApplicationServer(zone_name, db_shard_manager, clb_id, redis_conn)
                 all_servers.append(server); servers_by_zone[zone_name].append(server)
                 servers_for_clb[clb_id][server.server_id] = server
             temp_clb_counter += 1
    locked_print(f"Created {len(all_servers)} Application Servers.")

    # 3. Create CLBs
    clbs_by_zone = {zn: [] for zn in ZONE_NAMES.values()}; current_clb_ids = sorted(servers_for_clb.keys()); clb_id_idx = 0
    for zone_id in range(NUM_ZONES):
        zone_name = ZONE_NAMES[zone_id]
        for _ in range(CLUSTERS_PER_ZONE):
            if clb_id_idx < len(current_clb_ids):
                clb_id = current_clb_ids[clb_id_idx]; cluster_servers_dict = servers_for_clb[clb_id]
                clb = ClusterLoadBalancer(zone_name, cluster_servers_dict, redis_conn)
                if clb.clb_id != clb_id: exit(f"FATAL ERROR: CLB ID mismatch!")
                clbs_by_zone[zone_name].append(clb); clb_id_idx += 1
            else: break
    locked_print(f"Created {sum(len(clbs) for clbs in clbs_by_zone.values())} CLBs.")

    # 4. Create ZLBs
    zl_balancers = {}
    for zone_id, zone_name in ZONE_NAMES.items():
        zone_clbs = clbs_by_zone[zone_name]
        if zone_clbs: zl_balancers[zone_name] = ZoneLoadBalancer(zone_id, zone_name, zone_clbs, redis_conn)
    locked_print(f"Created {len(zl_balancers)} ZLBs.")

    # 5. Create PLB
    plb = PrimaryLoadBalancer(zl_balancers=zl_balancers)
    locked_print("--- System Setup Complete ---")
    return plb, db_shards # Return shards so we can shut them down later

# --- Simulation ---
def process_single_request(roll_num, plb):
    thread_name = threading.current_thread().name
    # locked_print(f"--- Starting processing for {roll_num} on {thread_name} ---")
    result = plb.handle_request(roll_num)
    locked_print(f"->-> Final Result for {roll_num} ({thread_name}): {result} <-<-")

if __name__ == "__main__":
    if 'redis_client' not in globals(): exit("Redis client not initialized.")

    primary_load_balancer, database_shards = setup_system(redis_client) # Get shards list

    test_roll_numbers = [ # Reduced number for clearer Bully logs
        "R1001", "R2340", "R5672", "R8881", "R9120",
        "R3331", "R4442", "R7770", "R1111", "R2222",
        "R0001", "R0000", "R0002", # Test requests during/after potential elections
    ] * 3 # Repeat a few times

    locked_print(f"\n--- Starting SIMULTANEOUS Request Simulation ({len(test_roll_numbers)} requests) ---")
    locked_print("--- Leader election & failures will run in background ---")
    start_time = time.time()

    request_threads = []
    for roll in test_roll_numbers:
        thread = threading.Thread(target=process_single_request, args=(roll, primary_load_balancer), daemon=True)
        request_threads.append(thread)
        thread.start()
        time.sleep(0.02) # Slightly more stagger

    locked_print(f"--- All {len(request_threads)} request threads started ---")
    locked_print("--- Waiting for simulation duration ---")

    # Let simulation run for a fixed duration to observe elections
    SIMULATION_DURATION = 20 # seconds
    time.sleep(SIMULATION_DURATION)
    locked_print(f"--- Simulation duration ({SIMULATION_DURATION}s) ended ---")

    # Signal background tasks in shards to stop
    for shard in database_shards:
        shard.shutdown()

    # Wait briefly for any remaining request threads (optional, depends on desired behavior)
    # Note: Since threads are daemon, they might exit abruptly if main thread finishes
    # A more robust shutdown would involve signaling request threads too.
    # locked_print("--- Waiting briefly for remaining request threads ---")
    # time.sleep(2) # Give threads a little more time to potentially finish

    end_time = time.time()
    locked_print("\n--- Simulation Complete ---")
    # Note: Not all threads might have finished if duration was too short
    locked_print(f"Simulated {len(test_roll_numbers)} requests concurrently over ~{end_time - start_time:.2f} seconds.")

    # Final Redis load check
    locked_print("\n--- Final Server Loads in Redis (Sample) ---")
    try:
        # Reset CLB counter to match IDs used
        ClusterLoadBalancer._clb_count = 0
        for clb_id_num in range(min(5, CLUSTERS_PER_ZONE * NUM_ZONES)):
             clb_id = f"CLB{clb_id_num:02d}"
             load_key = get_cluster_load_key(clb_id)
             loads = redis_client.zrange(load_key, 0, -1, withscores=True)
             if loads:
                 locked_print(f"  Cluster {clb_id} ({load_key}):")
                 non_zero = [(s, int(sc)) for s, sc in loads if float(sc) != 0]
                 if non_zero:
                      for server, score in non_zero: locked_print(f"    {server}: {score}")
                 else:
                      locked_print(f"    All servers: 0")
             else:
                 locked_print(f"  Cluster {clb_id} ({load_key}): No load data found.")
    except redis.exceptions.RedisError as e:
        locked_print(f"Redis error fetching final loads: {e}")
